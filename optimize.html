<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Optimization &#8212; revrand 1.0.0 documentation</title>
    
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Utilities" href="utils.html" />
    <link rel="prev" title="Validation Metrics" href="metrics.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="optimization">
<span id="optimize"></span><h1>Optimization<a class="headerlink" href="#optimization" title="Permalink to this headline">¶</a></h1>
<p>This module contains several stochastic gradient optimizers and decorators for
enhancing the functionality of these optimizers as well as the
<a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/optimize.html">scipy.optimize.minimize</a> optimizers.</p>
<div class="section" id="module-revrand.optimize.decorators">
<span id="optimizer-decorators"></span><h2>Optimizer Decorators<a class="headerlink" href="#module-revrand.optimize.decorators" title="Permalink to this headline">¶</a></h2>
<p>Optimizer Decorators.</p>
<dl class="function">
<dt id="revrand.optimize.decorators.flatten_args">
<code class="descclassname">revrand.optimize.decorators.</code><code class="descname">flatten_args</code><span class="sig-paren">(</span><em>shapes</em><span class="sig-paren">)</span><a class="headerlink" href="#revrand.optimize.decorators.flatten_args" title="Permalink to this definition">¶</a></dt>
<dd><p>Decorator to flatten structured arguments to a function.</p>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nd">@flatten_args</span><span class="p">([(</span><span class="mi">5</span><span class="p">,),</span> <span class="p">()])</span>
<span class="gp">... </span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="o">.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">lambda_</span> <span class="o">*</span> <span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">6</span><span class="p">,</span> <span class="o">-.</span><span class="mi">2</span><span class="p">,</span> <span class="o">.</span><span class="mi">9</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">])),</span> <span class="o">.</span><span class="mi">546</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">6</span><span class="p">,</span> <span class="o">-.</span><span class="mi">2</span><span class="p">,</span> <span class="o">.</span><span class="mi">9</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lambda_</span> <span class="o">=</span> <span class="o">.</span><span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="o">.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">lambda_</span> <span class="o">*</span> <span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">),</span> <span class="o">.</span><span class="mi">546</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
<p>Some other curious applications</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">operator</span> <span class="k">import</span> <span class="n">mul</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">flatten_args_dec</span> <span class="o">=</span> <span class="n">flatten_args</span><span class="p">([(),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">func</span> <span class="o">=</span> <span class="n">flatten_args_dec</span><span class="p">(</span><span class="n">mul</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">func</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">3.1</span><span class="p">,</span> <span class="o">.</span><span class="mi">6</span><span class="p">,</span> <span class="mf">1.71</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2</span><span class="p">]))</span>
<span class="go">array([ 1.86 ,  5.301, -3.72 ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="mf">3.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">.</span><span class="mi">6</span><span class="p">,</span> <span class="mf">1.71</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2</span><span class="p">])</span>
<span class="go">array([ 1.86 ,  5.301, -3.72 ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">flatten_args_dec</span> <span class="o">=</span> <span class="n">flatten_args</span><span class="p">([(</span><span class="mi">9</span><span class="p">,),</span> <span class="p">(</span><span class="mi">15</span><span class="p">,)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">func</span> <span class="o">=</span> <span class="n">flatten_args_dec</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">))</span> <span class="c1"># 7 - (-5) / 0.5 = 24 = 9 + 15</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(15, 9)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
<span class="go">array([-5. , -4.5, -4. , -3.5, -3. , -2.5, -2. , -1.5, -1. ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(15, 9)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="go">array([-0.5,  0. ,  0.5,  1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,</span>
<span class="go">        5. ,  5.5,  6. ,  6.5])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="revrand.optimize.decorators.flatten_func_grad">
<code class="descclassname">revrand.optimize.decorators.</code><code class="descname">flatten_func_grad</code><span class="sig-paren">(</span><em>func</em><span class="sig-paren">)</span><a class="headerlink" href="#revrand.optimize.decorators.flatten_func_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Decorator to flatten structured gradients and return objective.</p>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">cost</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">sq_norm</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="o">.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">lambda_</span> <span class="o">*</span> <span class="n">sq_norm</span><span class="p">,</span> <span class="p">[</span><span class="n">lambda_</span> <span class="o">*</span> <span class="n">w</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">sq_norm</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">val</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="n">cost</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="o">-.</span><span class="mi">2</span><span class="p">]),</span> <span class="o">.</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="mf">0.0375</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">len</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad_w</span><span class="p">,</span> <span class="n">grad_lambda</span> <span class="o">=</span> <span class="n">grad</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">grad_w</span><span class="p">)</span>
<span class="go">(3,)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">grad_lambda</span><span class="p">)</span>
<span class="go">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad_w</span>
<span class="go">array([ 0.125,  0.025, -0.05 ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">grad_lambda</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cost_new</span> <span class="o">=</span> <span class="n">flatten_func_grad</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">val_new</span><span class="p">,</span> <span class="n">grad_new</span> <span class="o">=</span> <span class="n">cost_new</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="o">-.</span><span class="mi">2</span><span class="p">]),</span> <span class="o">.</span><span class="mi">25</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">val</span> <span class="o">==</span> <span class="n">val_new</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad_new</span>
<span class="go">array([ 0.125,  0.025, -0.05 ,  0.15 ])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="revrand.optimize.decorators.flatten_grad">
<code class="descclassname">revrand.optimize.decorators.</code><code class="descname">flatten_grad</code><span class="sig-paren">(</span><em>func</em><span class="sig-paren">)</span><a class="headerlink" href="#revrand.optimize.decorators.flatten_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Decorator to flatten structured gradients.</p>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">cost</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">sq_norm</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">lambda_</span> <span class="o">*</span> <span class="n">w</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">sq_norm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad</span> <span class="o">=</span> <span class="n">cost</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="o">-.</span><span class="mi">2</span><span class="p">]),</span> <span class="o">.</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">len</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad_w</span><span class="p">,</span> <span class="n">grad_lambda</span> <span class="o">=</span> <span class="n">grad</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">grad_w</span><span class="p">)</span>
<span class="go">(3,)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">grad_lambda</span><span class="p">)</span>
<span class="go">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad_w</span>
<span class="go">array([ 0.125,  0.025, -0.05 ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">grad_lambda</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cost_new</span> <span class="o">=</span> <span class="n">flatten_grad</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad_new</span> <span class="o">=</span> <span class="n">cost_new</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="o">-.</span><span class="mi">2</span><span class="p">]),</span> <span class="o">.</span><span class="mi">25</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad_new</span>
<span class="go">array([ 0.125,  0.025, -0.05 ,  0.15 ])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="revrand.optimize.decorators.logtrick_minimizer">
<code class="descclassname">revrand.optimize.decorators.</code><code class="descname">logtrick_minimizer</code><span class="sig-paren">(</span><em>minimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#revrand.optimize.decorators.logtrick_minimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Log-Trick decorator for optimizers.</p>
<p>This decorator implements the &#8220;log trick&#8221; for optimizing positive bounded
variables. It will apply this trick for any variables that correspond to a
Positive() bound.</p>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="k">import</span> <span class="n">minimize</span> <span class="k">as</span> <span class="n">sp_min</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">..btypes</span> <span class="k">import</span> <span class="n">Bound</span><span class="p">,</span> <span class="n">Positive</span>
</pre></div>
</div>
<p>Here is an example where we may want to enforce a particular parameter or
parameters to be strictly greater than zero,</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">cost</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">sq_norm</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="o">.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">lambda_</span> <span class="o">*</span> <span class="n">sq_norm</span><span class="p">,</span> <span class="n">lambda_</span> <span class="o">*</span> <span class="n">w</span>
</pre></div>
</div>
<p>Now let&#8217;s enforce that the <cite>w</cite> are positive,</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="p">[</span><span class="n">Positive</span><span class="p">(),</span> <span class="n">Positive</span><span class="p">(),</span> <span class="n">Positive</span><span class="p">()]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_min</span> <span class="o">=</span> <span class="n">logtrick_minimizer</span><span class="p">(</span><span class="n">sp_min</span><span class="p">)</span>
</pre></div>
</div>
<p>Initial values</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">w_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lambda_0</span> <span class="o">=</span> <span class="o">.</span><span class="mi">25</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">new_min</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="n">w_0</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">lambda_0</span><span class="p">,),</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
<span class="gp">... </span>              <span class="n">method</span><span class="o">=</span><span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">0</span>
<span class="go">array([ True,  True,  True], dtype=bool)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This decorator only works on unstructured optimizers. However, it can be
use with structured_minimizer, so long as it is the inner wrapper.</p>
</div>
</dd></dl>

<dl class="function">
<dt id="revrand.optimize.decorators.logtrick_sgd">
<code class="descclassname">revrand.optimize.decorators.</code><code class="descname">logtrick_sgd</code><span class="sig-paren">(</span><em>sgd</em><span class="sig-paren">)</span><a class="headerlink" href="#revrand.optimize.decorators.logtrick_sgd" title="Permalink to this definition">¶</a></dt>
<dd><p>Log-Trick decorator for stochastic gradients.</p>
<p>This decorator implements the &#8220;log trick&#8221; for optimizing positive bounded
variables using SGD. It will apply this trick for any variables that
correspond to a Positive() bound.</p>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">..optimize</span> <span class="k">import</span> <span class="n">sgd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">..btypes</span> <span class="k">import</span> <span class="n">Bound</span><span class="p">,</span> <span class="n">Positive</span>
</pre></div>
</div>
<p>Here is an example where we may want to enforce a particular parameter or
parameters to be strictly greater than zero,</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">cost</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
<span class="gp">... </span>    <span class="n">y_est</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">ww</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">obj</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_est</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">N</span> <span class="o">+</span> <span class="n">lambda_</span> <span class="o">*</span> <span class="n">ww</span>
<span class="gp">... </span>    <span class="n">gradw</span> <span class="o">=</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_est</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">lambda_</span> <span class="o">*</span> <span class="n">w</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">obj</span><span class="p">,</span> <span class="n">gradw</span>
</pre></div>
</div>
<p>Now let&#8217;s enforce that the <cite>w</cite> are positive,</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="p">[</span><span class="n">Positive</span><span class="p">(),</span> <span class="n">Positive</span><span class="p">()]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_sgd</span> <span class="o">=</span> <span class="n">logtrick_sgd</span><span class="p">(</span><span class="n">sgd</span><span class="p">)</span>
</pre></div>
</div>
<p>Data</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">100</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)])</span><span class="o">.</span><span class="n">T</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">y</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">X</span><span class="p">))</span>
</pre></div>
</div>
<p>Initial values</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">w_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lambda_0</span> <span class="o">=</span> <span class="o">.</span><span class="mi">25</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">new_sgd</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="n">w_0</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">lambda_0</span><span class="p">,),</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
<span class="gp">... </span>              <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">eval_obj</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">0</span>
<span class="go">array([ True,  True], dtype=bool)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This decorator only works on unstructured optimizers. However, it can be
use with structured_minimizer, so long as it is the inner wrapper.</p>
</div>
</dd></dl>

<dl class="function">
<dt id="revrand.optimize.decorators.structured_minimizer">
<code class="descclassname">revrand.optimize.decorators.</code><code class="descname">structured_minimizer</code><span class="sig-paren">(</span><em>minimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#revrand.optimize.decorators.structured_minimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Allow an optimizer to accept nested sequences of Parameters to optimize.</p>
<p>This decorator can intepret the <code class="code docutils literal"><span class="pre">Parameter</span></code> objects in <cite>btypes.py</cite>,
and can accept nested sequences of <em>any</em> structure of these objects to
optimise!</p>
<p>It can also optionally evaluate <em>random starts</em> (i.e. random starting
candidates) if the parameter objects have been initialised with
distributions. For this, two additional parameters are exposed in the
<code class="code docutils literal"><span class="pre">minimizer</span></code> interface.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>fun</strong> (<em>callable</em>) &#8211; objective function that takes in arbitrary ndarrays, floats or nested
sequences of these.</li>
<li><strong>parameters</strong> (<em></em><em>(</em><em>nested</em><em>) </em><em>sequences of Parameter objects</em>) &#8211; Initial guess of the parameters of the objective function</li>
<li><strong>nstarts</strong> (<em>int</em><em>, </em><em>optional</em>) &#8211; The number random starting candidates for optimisation to evaluate.
This will only happen for <code class="code docutils literal"><span class="pre">nstarts</span> <span class="pre">&gt;</span> <span class="pre">0</span></code> and if at least one
<code class="code docutils literal"><span class="pre">Parameter</span></code> object is random.</li>
<li><strong>random_state</strong> (<em>None</em><em>, </em><em>int</em><em> or </em><em>RandomState</em><em>, </em><em>optional</em>) &#8211; random seed</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="k">import</span> <span class="n">minimize</span> <span class="k">as</span> <span class="n">sp_min</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">..btypes</span> <span class="k">import</span> <span class="n">Parameter</span><span class="p">,</span> <span class="n">Bound</span>
</pre></div>
</div>
<p>Define a cost function that returns a pair. The first element is the cost
value and the second element is the gradient represented by a tuple. Even
if the cost is a function of a single variable, the gradient must be a
tuple containing one element.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">cost</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">sq_norm</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="o">.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">lambda_</span> <span class="o">*</span> <span class="n">sq_norm</span><span class="p">,</span> <span class="p">(</span><span class="n">lambda_</span> <span class="o">*</span> <span class="n">w</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">sq_norm</span><span class="p">)</span>
</pre></div>
</div>
<p>Augment the Scipy optimizer to take structured inputs</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">new_min</span> <span class="o">=</span> <span class="n">structured_minimizer</span><span class="p">(</span><span class="n">sp_min</span><span class="p">)</span>
</pre></div>
</div>
<p>Constant Initial values</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">w_0</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">]),</span> <span class="n">Bound</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lambda_0</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="o">.</span><span class="mi">25</span><span class="p">,</span> <span class="n">Bound</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">new_min</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="p">(</span><span class="n">w_0</span><span class="p">,</span> <span class="n">lambda_0</span><span class="p">),</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res_w</span><span class="p">,</span> <span class="n">res_lambda</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">x</span>
</pre></div>
</div>
<p>Random Initial values</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">norm</span><span class="p">,</span> <span class="n">gamma</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w_0</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">norm</span><span class="p">(),</span> <span class="n">Bound</span><span class="p">(),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lambda_0</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">gamma</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">Bound</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">new_min</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="p">(</span><span class="n">w_0</span><span class="p">,</span> <span class="n">lambda_0</span><span class="p">),</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">... </span>              <span class="n">nstarts</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res_w</span><span class="p">,</span> <span class="n">res_lambda</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">x</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="revrand.optimize.decorators.structured_sgd">
<code class="descclassname">revrand.optimize.decorators.</code><code class="descname">structured_sgd</code><span class="sig-paren">(</span><em>sgd</em><span class="sig-paren">)</span><a class="headerlink" href="#revrand.optimize.decorators.structured_sgd" title="Permalink to this definition">¶</a></dt>
<dd><p>Allow an SGD to accept nested sequences of Parameters to optimize.</p>
<p>This decorator can intepret the <code class="code docutils literal"><span class="pre">Parameter</span></code> objects in <cite>btypes.py</cite>,
and can accept nested sequences of <em>any</em> structure of these objects to
optimise!</p>
<p>It can also optionally evaluate <em>random starts</em> (i.e. random starting
candidates) if the parameter objects have been initialised with
distributions. For this, an additional parameter is exposed in the
<code class="code docutils literal"><span class="pre">minimizer</span></code> interface.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>fun</strong> (<em>callable</em>) &#8211; objective function that takes in arbitrary ndarrays, floats or nested
sequences of these.</li>
<li><strong>parameters</strong> (<em></em><em>(</em><em>nested</em><em>) </em><em>sequences of Parameter objects</em>) &#8211; Initial guess of the parameters of the objective function</li>
<li><strong>nstarts</strong> (<em>int</em><em>, </em><em>optional</em>) &#8211; The number random starting candidates for optimisation to evaluate.
This will only happen for <code class="code docutils literal"><span class="pre">nstarts</span> <span class="pre">&gt;</span> <span class="pre">0</span></code> and if at least one
<code class="code docutils literal"><span class="pre">Parameter</span></code> object is random.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">..optimize</span> <span class="k">import</span> <span class="n">sgd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">..btypes</span> <span class="k">import</span> <span class="n">Parameter</span><span class="p">,</span> <span class="n">Bound</span>
</pre></div>
</div>
<p>Define a cost function that returns a pair. The first element is the cost
value and the second element is the gradient represented by a sequence.
Even if the cost is a function of a single variable, the gradient must be a
sequence containing one element.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">cost</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
<span class="gp">... </span>    <span class="n">y_est</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">ww</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">obj</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_est</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">N</span> <span class="o">+</span> <span class="n">lambda_</span> <span class="o">*</span> <span class="n">ww</span>
<span class="gp">... </span>    <span class="n">gradw</span> <span class="o">=</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_est</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">lambda_</span> <span class="o">*</span> <span class="n">w</span>
<span class="gp">... </span>    <span class="n">gradl</span> <span class="o">=</span> <span class="n">ww</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">obj</span><span class="p">,</span> <span class="p">[</span><span class="n">gradw</span><span class="p">,</span> <span class="n">gradl</span><span class="p">]</span>
</pre></div>
</div>
<p>Augment the SGD optimizer to take structured inputs</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">new_sgd</span> <span class="o">=</span> <span class="n">structured_sgd</span><span class="p">(</span><span class="n">sgd</span><span class="p">)</span>
</pre></div>
</div>
<p>Data</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">100</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)])</span><span class="o">.</span><span class="n">T</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">y</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">X</span><span class="p">))</span>
</pre></div>
</div>
<p>Constant Initial values</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">w_0</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]),</span> <span class="n">Bound</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lambda_0</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="o">.</span><span class="mi">25</span><span class="p">,</span> <span class="n">Bound</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">new_sgd</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="p">[</span><span class="n">w_0</span><span class="p">,</span> <span class="n">lambda_0</span><span class="p">],</span> <span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>              <span class="n">eval_obj</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res_w</span><span class="p">,</span> <span class="n">res_lambda</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">x</span>
</pre></div>
</div>
<p>Random Initial values</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">norm</span><span class="p">,</span> <span class="n">gamma</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w_0</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">norm</span><span class="p">(),</span> <span class="n">Bound</span><span class="p">(),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lambda_0</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">gamma</span><span class="p">(</span><span class="mf">1.</span><span class="p">),</span> <span class="n">Bound</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">new_sgd</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="p">[</span><span class="n">w_0</span><span class="p">,</span> <span class="n">lambda_0</span><span class="p">],</span> <span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>              <span class="n">eval_obj</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nstarts</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res_w</span><span class="p">,</span> <span class="n">res_lambda</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">x</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="module-revrand.optimize.sgd">
<span id="stochastic-gradients"></span><h2>Stochastic Gradients<a class="headerlink" href="#module-revrand.optimize.sgd" title="Permalink to this headline">¶</a></h2>
<p>Stochastic Gradient Descent.</p>
<dl class="class">
<dt id="revrand.optimize.sgd.AdaDelta">
<em class="property">class </em><code class="descclassname">revrand.optimize.sgd.</code><code class="descname">AdaDelta</code><span class="sig-paren">(</span><em>rho=0.1</em>, <em>epsilon=1e-05</em><span class="sig-paren">)</span><a class="headerlink" href="#revrand.optimize.sgd.AdaDelta" title="Permalink to this definition">¶</a></dt>
<dd><p>AdaDelta Algorithm.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>rho</strong> (<em>float</em><em>, </em><em>optional</em>) &#8211; smoothing/decay rate parameter, must be [0, 1].</li>
<li><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) &#8211; &#8220;jitter&#8221; term to ensure continued learning (should be small).</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="revrand.optimize.sgd.AdaDelta.reset">
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#revrand.optimize.sgd.AdaDelta.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset the state of this updater for a new optimisation problem.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="revrand.optimize.sgd.AdaGrad">
<em class="property">class </em><code class="descclassname">revrand.optimize.sgd.</code><code class="descname">AdaGrad</code><span class="sig-paren">(</span><em>eta=1</em>, <em>epsilon=1e-06</em><span class="sig-paren">)</span><a class="headerlink" href="#revrand.optimize.sgd.AdaGrad" title="Permalink to this definition">¶</a></dt>
<dd><p>AdaGrad Algorithm.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>eta</strong> (<em>float</em><em>, </em><em>optional</em>) &#8211; smoothing/decay rate parameter, must be [0, 1].</li>
<li><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) &#8211; small constant term to prevent divide-by-zeros</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="revrand.optimize.sgd.AdaGrad.reset">
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#revrand.optimize.sgd.AdaGrad.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset the state of this updater for a new optimisation problem.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="revrand.optimize.sgd.Adam">
<em class="property">class </em><code class="descclassname">revrand.optimize.sgd.</code><code class="descname">Adam</code><span class="sig-paren">(</span><em>alpha=0.01</em>, <em>beta1=0.9</em>, <em>beta2=0.99</em>, <em>epsilon=1e-08</em><span class="sig-paren">)</span><a class="headerlink" href="#revrand.optimize.sgd.Adam" title="Permalink to this definition">¶</a></dt>
<dd><p>Adam Algorithm.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>alpha</strong> (<em>float</em><em>, </em><em>optional</em>) &#8211; stepsize to give the update.</li>
<li><strong>beta1</strong> (<em>float</em><em>, </em><em>optional</em>) &#8211; smoothing/decay rate parameter for the gradient, must be [0, 1].</li>
<li><strong>beta2</strong> (<em>float</em><em>, </em><em>optional</em>) &#8211; smoothing/decay rate parameter for the squared gradient, must be
[0, 1].</li>
<li><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) &#8211; &#8220;jitter&#8221; term to ensure continued learning (should be small).</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="revrand.optimize.sgd.Adam.reset">
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#revrand.optimize.sgd.Adam.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset the state of this updater for a new optimisation problem.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="revrand.optimize.sgd.Momentum">
<em class="property">class </em><code class="descclassname">revrand.optimize.sgd.</code><code class="descname">Momentum</code><span class="sig-paren">(</span><em>rho=0.5</em>, <em>eta=0.01</em><span class="sig-paren">)</span><a class="headerlink" href="#revrand.optimize.sgd.Momentum" title="Permalink to this definition">¶</a></dt>
<dd><p>Momentum Algorithm.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>rho</strong> (<em>float</em><em>, </em><em>optional</em>) &#8211; smoothing/decay rate parameter, must be [0, 1].</li>
<li><strong>eta</strong> (<em>float</em><em>, </em><em>optional</em>) &#8211; weight to give to the momentum term</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="revrand.optimize.sgd.Momentum.reset">
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#revrand.optimize.sgd.Momentum.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset the state of this updater for a new optimisation problem.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="revrand.optimize.sgd.SGDUpdater">
<em class="property">class </em><code class="descclassname">revrand.optimize.sgd.</code><code class="descname">SGDUpdater</code><span class="sig-paren">(</span><em>eta=0.1</em><span class="sig-paren">)</span><a class="headerlink" href="#revrand.optimize.sgd.SGDUpdater" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for SGD learning rate algorithms.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>eta</strong> (<em>float</em><em>, </em><em>optional</em>) &#8211; The learning rate applied to every gradient step.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="revrand.optimize.sgd.SGDUpdater.reset">
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#revrand.optimize.sgd.SGDUpdater.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset the state of this updater for a new optimisation problem.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="revrand.optimize.sgd.gen_batch">
<code class="descclassname">revrand.optimize.sgd.</code><code class="descname">gen_batch</code><span class="sig-paren">(</span><em>data</em>, <em>batch_size</em>, <em>maxiter=inf</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="headerlink" href="#revrand.optimize.sgd.gen_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Create random batches for Stochastic gradients.</p>
<p>Batch index generator for SGD that will yeild random batches for a
a defined number of iterations, which can be infinite. This generator makes
consecutive passes through the data, drawing without replacement on each
pass.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<em>ndarray</em><em> or </em><em>sequence of ndarrays</em>) &#8211; The data, can be a matrix X, (X,y) tuples etc</li>
<li><strong>batch_size</strong> (<em>int</em>) &#8211; number of data points in each batch.</li>
<li><strong>maxiter</strong> (<em>int</em><em>, </em><em>optional</em>) &#8211; The number of iterations</li>
<li><strong>random_state</strong> (<em>int</em><em> or </em><em>RandomState</em><em>, </em><em>optional</em>) &#8211; random seed</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Yields:</th><td class="field-body"><p class="first last"><em>ndarray or sequence</em> &#8211; with each array length <code class="docutils literal"><span class="pre">batch_size</span></code>, i.e. a subset of data.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="revrand.optimize.sgd.normalize_bound">
<code class="descclassname">revrand.optimize.sgd.</code><code class="descname">normalize_bound</code><span class="sig-paren">(</span><em>bound</em><span class="sig-paren">)</span><a class="headerlink" href="#revrand.optimize.sgd.normalize_bound" title="Permalink to this definition">¶</a></dt>
<dd><p>Replace <code class="docutils literal"><span class="pre">None</span></code> with + or - inf in bound tuples.</p>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">normalize_bound</span><span class="p">((</span><span class="mf">2.6</span><span class="p">,</span> <span class="mf">7.2</span><span class="p">))</span>
<span class="go">(2.6, 7.2)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">normalize_bound</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="mf">7.2</span><span class="p">))</span>
<span class="go">(-inf, 7.2)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">normalize_bound</span><span class="p">((</span><span class="mf">2.6</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
<span class="go">(2.6, inf)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">normalize_bound</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
<span class="go">(-inf, inf)</span>
</pre></div>
</div>
<p>This operation is idempotent:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">normalize_bound</span><span class="p">((</span><span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">),</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)))</span>
<span class="go">(-inf, inf)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="revrand.optimize.sgd.sgd">
<code class="descclassname">revrand.optimize.sgd.</code><code class="descname">sgd</code><span class="sig-paren">(</span><em>fun</em>, <em>x0</em>, <em>data</em>, <em>args=()</em>, <em>bounds=None</em>, <em>batch_size=10</em>, <em>maxiter=5000</em>, <em>updater=None</em>, <em>eval_obj=False</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="headerlink" href="#revrand.optimize.sgd.sgd" title="Permalink to this definition">¶</a></dt>
<dd><p>Stochastic Gradient Descent.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>fun</strong> (<em>callable</em>) &#8211; the function to <em>minimize</em>, this must have the signature <code class="docutils literal"><span class="pre">[obj,]</span></code>
grad = fun(x, data, ...)`, where the <code class="docutils literal"><span class="pre">eval_obj</span></code> argument tells
<code class="docutils literal"><span class="pre">sgd</span></code> if an objective function value is going to be returned by
<code class="docutils literal"><span class="pre">fun</span></code>.</li>
<li><strong>x0</strong> (<em>ndarray</em>) &#8211; a sequence/1D array of initial values for the parameters to learn.</li>
<li><strong>data</strong> (<em>ndarray</em>) &#8211; a numpy array or sequence of data to input into <code class="docutils literal"><span class="pre">fun</span></code>. This will
be split along the first axis (axis=0), and then input into
<code class="docutils literal"><span class="pre">fun</span></code>.</li>
<li><strong>args</strong> (<em>sequence</em><em>, </em><em>optional</em>) &#8211; an optional sequence of arguments to give to fun.</li>
<li><strong>bounds</strong> (<em>sequence</em><em>, </em><em>optional</em>) &#8211; Bounds for variables, (min, max) pairs for each element in x, defining
the bounds on that parameter.  Use None for one of min or max when
there is no bound in that direction.</li>
<li><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) &#8211; The number of observations in an SGD batch.</li>
<li><strong>maxiter</strong> (<em>int</em><em>, </em><em>optional</em>) &#8211; Number of mini-batch iterations before optimization terminates.</li>
<li><strong>updater</strong> (<a class="reference internal" href="#revrand.optimize.sgd.SGDUpdater" title="revrand.optimize.sgd.SGDUpdater"><em>SGDUpdater</em></a><em>, </em><em>optional</em>) &#8211; The type of gradient update to use, by default this is Adam.</li>
<li><strong>eval_obj</strong> (<em>bool</em><em>, </em><em>optional</em>) &#8211; This indicates whether or not <code class="docutils literal"><span class="pre">fun</span></code> also evaluates and returns
the objective function value. If this is true, <code class="docutils literal"><span class="pre">fun</span></code> must return
<code class="docutils literal"><span class="pre">(obj,</span> <span class="pre">grad)</span></code> and then a list of objective function values is
also returned.</li>
<li><strong>random_state</strong> (<em>int</em><em> or </em><em>RandomState</em><em>, </em><em>optional</em>) &#8211; random seed</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><p><strong>res</strong> &#8211;</p>
<dl class="docutils">
<dt>x <span class="classifier-delimiter">:</span> <span class="classifier">narray</span></dt>
<dd><p class="first last">the final result</p>
</dd>
<dt>norms <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd><p class="first last">the list of gradient norms</p>
</dd>
<dt>message <span class="classifier-delimiter">:</span> <span class="classifier">str</span></dt>
<dd><p class="first last">the convergence condition (&#8216;maxiter reached&#8217; or error)</p>
</dd>
<dt>objs <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd><p class="first last">the list of objective function evaluations if <code class="docutils literal"><span class="pre">eval_obj</span></code>
is True.</p>
</dd>
<dt>fun <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">the final objective function evaluation if <code class="docutils literal"><span class="pre">eval_obj</span></code> is
True.</p>
</dd>
</dl>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">OptimizeResult</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">revrand</a></h1>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=NICTA&repo=revrand&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





    

<p>
<a href="https://travis-ci.org/NICTA/revrand">
    <img
        alt="https://secure.travis-ci.org/NICTA/revrand.svg?branch=master"
        src="https://secure.travis-ci.org/NICTA/revrand.svg?branch=master"
    />
</a>
</p>




    

<p>
<a href="https://codecov.io/github/NICTA/revrand">
    <img
    alt="https://codecov.io/github/NICTA/revrand/coverage.svg?branch=master"
    src="https://codecov.io/github/NICTA/revrand/coverage.svg?branch=master"
    />
</a>
</p>
<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quickstart Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="basis_funcs.html">Basis Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="slm.html">Standard Linear Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="glm.html">Generalized Linear Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="likelihoods.html">Likelihood Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="btypes.html">Bound and Parameter Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">Validation Metrics</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Optimization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-revrand.optimize.decorators">Optimizer Decorators</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-revrand.optimize.sgd">Stochastic Gradients</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="mathfun.html">Math Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo.html">Demos</a></li>
<li class="toctree-l1"><a class="reference internal" href="dev/index.html">Developer&#8217;s Guide</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="metrics.html" title="previous chapter">Validation Metrics</a></li>
      <li>Next: <a href="utils.html" title="next chapter">Utilities</a></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/optimize.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Daniel Steinberg, Louis Tiao, Lachlan McCalman, Alistair Reid, Simon O'Callaghan.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.5.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
      |
      <a href="_sources/optimize.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    
    <a href="https://github.com/NICTA/revrand" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>