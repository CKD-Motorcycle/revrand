<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Generalised Linear Model &mdash; revrand 0.4.1 documentation</title>
    
    <link rel="stylesheet" href="_static/pyramid.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.4.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="revrand 0.4.1 documentation" href="index.html" />
    <link rel="next" title="Likelihood Classes" href="likelihoods.html" />
    <link rel="prev" title="Standard Linear Model" href="slm.html" />
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Neuton&amp;subset=latin" type="text/css" media="screen" charset="utf-8" />
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Nobile:regular,italic,bold,bolditalic&amp;subset=latin" type="text/css" media="screen" charset="utf-8" />
<!--[if lte IE 6]>
<link rel="stylesheet" href="_static/ie6.css" type="text/css" media="screen" charset="utf-8" />
<![endif]-->

  </head>
  <body role="document">

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="likelihoods.html" title="Likelihood Classes"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="slm.html" title="Standard Linear Model"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">revrand 0.4.1 documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="module-revrand.glm">
<span id="generalised-linear-model"></span><h1>Generalised Linear Model<a class="headerlink" href="#module-revrand.glm" title="Permalink to this headline">¶</a></h1>
<p>Implementation of Bayesian GLMs with nonparametric variational inference <a class="footnote-reference" href="#id2" id="id1">[1]</a>,
with a few modifications and tweaks.</p>
<table class="docutils footnote" frame="void" id="id2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td><em>(<a class="fn-backref" href="#id1">1</a>, <a class="fn-backref" href="#id3">2</a>, <a class="fn-backref" href="#id4">3</a>)</em> Gershman, S., Hoffman, M., &amp; Blei, D. &#8220;Nonparametric variational
inference&#8221;. arXiv preprint arXiv:1206.4665 (2012).</td></tr>
</tbody>
</table>
<dl class="function">
<dt id="revrand.glm.learn">
<code class="descclassname">revrand.glm.</code><code class="descname">learn</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>likelihood</em>, <em>basis</em>, <em>regulariser=&lt;revrand.btypes.Parameter object&gt;</em>, <em>likelihood_args=()</em>, <em>postcomp=10</em>, <em>use_sgd=True</em>, <em>maxit=1000</em>, <em>tol=1e-07</em>, <em>batch_size=100</em>, <em>rho=0.9</em>, <em>epsilon=1e-05</em><span class="sig-paren">)</span><a class="headerlink" href="#revrand.glm.learn" title="Permalink to this definition">¶</a></dt>
<dd><p>Learn the parameters of a Bayesian generalised linear model (GLM).</p>
<p>The learning algorithm uses nonparametric variational inference <a class="footnote-reference" href="#id2" id="id3">[1]</a>, and
optionally stochastic gradients.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; (N, d) array input dataset (N samples, d dimensions).</li>
<li><strong>y</strong> (<em>ndarray</em>) &#8211; (N,) array targets (N samples)</li>
<li><strong>likelihood</strong> (<em>Object</em>) &#8211; A likelihood object, see the likelihoods module.</li>
<li><strong>basis</strong> (<em>Basis</em>) &#8211; A basis object, see the basis_functions module.</li>
<li><strong>regulariser</strong> (<em>Parameter, optional</em>) &#8211; weight regulariser (variance) initial value.</li>
<li><strong>likelihood_args</strong> (<em>sequence, optional</em>) &#8211; sequence of arguments to pass to the likelihood function. These
are non-learnable parameters. They can be scalars or arrays of
length N.</li>
<li><strong>postcomp</strong> (<em>int, optional</em>) &#8211; Number of diagonal Gaussian components to use to approximate the
posterior distribution.</li>
<li><strong>use_sgd</strong> (<em>bool, optional</em>) &#8211; If <code class="code docutils literal"><span class="pre">True</span></code> then use SGD (Adadelta) optimisation instead of
L-BFGS.</li>
<li><strong>maxit</strong> (<em>int, optional</em>) &#8211; Maximum number of iterations of the optimiser to run. If
<code class="code docutils literal"><span class="pre">use_sgd</span></code> is <code class="code docutils literal"><span class="pre">True</span></code> then this is the number of complete
passes through the data before optimization terminates.</li>
<li><strong>tol</strong> (<em>float, optional</em>) &#8211; Optimiser relative tolerance convergence criterion (only if L-BFGS
is used as the optimiser).</li>
<li><strong>batch_size</strong> (<em>int, optional</em>) &#8211; number of observations to use per SGD batch. Ignored if
<code class="code docutils literal"><span class="pre">use_sgd=False</span></code>.</li>
<li><strong>rho</strong> (<em>float, optional</em>) &#8211; SGD decay rate, must be [0, 1]. Ignored if <code class="code docutils literal"><span class="pre">use_sgd=False</span></code>.</li>
<li><strong>epsilon</strong> (<em>float, optional</em>) &#8211; Jitter term for adadelta SGD. Ignored if <code class="code docutils literal"><span class="pre">use_sgd=False</span></code>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>m</strong> (<em>ndarray</em>) &#8211; (D, postcomp) array of posterior weight means (D is the dimension
of the features).</li>
<li><strong>C</strong> (<em>ndarray</em>) &#8211; (D, postcomp) array of posterior weight variances.</li>
<li><strong>likelihood_hypers</strong> (<em>sequence</em>) &#8211; learned sequence of likelihood object hyperparameters.</li>
<li><strong>basis_hypers</strong> (<em>sequence</em>) &#8211; learned sequence of basis object hyperparameters.</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>This approximates the posterior distribution over the weights with
a mixture of Gaussians:</p>
<div class="math">
\[\mathbf{w} \sim \frac{1}{K} \sum^K_{k=1}
    \mathcal{N}(\mathbf{m_k}, \boldsymbol{\Psi}_k)\]</div>
<p>where,</p>
<div class="math">
\[\boldsymbol{\Psi}_k = \text{diag}([\Psi_{k,1}, \ldots,
    \Psi_{k,D}]).\]</div>
<p>This is so arbitrary likelihoods can be used with this algorithm, while
still mainting flexible and tractable non-Gaussian posteriors.
Additionaly this has the benefit that we have a reduced number of
parameters to optimise (compared with full covariance Gaussians).</p>
<p>The main differences between this implementation and the GLM in <a class="footnote-reference" href="#id2" id="id4">[1]</a>
are:</p>
<blockquote>
<div><ul class="simple">
<li>We use diagonal mixtures, as opposed to isotropic.</li>
<li>We do not cycle between optimising eq. 10 and 11 (objectives L1
and L2) in the paper. We use the full objective L2 for
everything, including the posterior means, and we optimise all
parameters together.</li>
</ul>
</div></blockquote>
<p>Even though these changes make learning a little slower, and require
third derivatives of the likelihoods, we obtain better results and we
can use SGD straight-forwardly.</p>
<p>This uses the python logging module for displaying learning status.
To view these messages have something like,</p>
<div class="code highlight-default"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>
<span class="n">log</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>
</pre></div>
</div>
<p>in your calling code.</p>
</dd></dl>

<dl class="function">
<dt id="revrand.glm.predict_cdf">
<code class="descclassname">revrand.glm.</code><code class="descname">predict_cdf</code><span class="sig-paren">(</span><em>quantile</em>, <em>Xs</em>, <em>likelihood</em>, <em>basis</em>, <em>m</em>, <em>C</em>, <em>likelihood_hypers</em>, <em>basis_hypers</em>, <em>likelihood_args=()</em>, <em>nsamples=100</em><span class="sig-paren">)</span><a class="headerlink" href="#revrand.glm.predict_cdf" title="Permalink to this definition">¶</a></dt>
<dd><p>Predictive cumulative density function of a Bayesian GLM.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>quantile</strong> (<em>float</em>) &#8211; The predictive probability, <span class="math">\(p(y^* \leq \text{quantile} |
\mathbf{X}, y)\)</span>.</li>
<li><strong>Xs</strong> (<em>ndarray</em>) &#8211; (Ns,d) array query input dataset (Ns samples, D dimensions).</li>
<li><strong>likelihood</strong> (<em>Object</em>) &#8211; A likelihood object, see the likelihoods module.</li>
<li><strong>basis</strong> (<em>Basis</em>) &#8211; A basis object, see the basis_functions module.</li>
<li><strong>m</strong> (<em>ndarray</em>) &#8211; (D,) array of regression weights (posterior).</li>
<li><strong>C</strong> (<em>ndarray</em>) &#8211; (D,) or (D, D) array of regression weight covariances (posterior).</li>
<li><strong>likelihood_hypers</strong> (<em>sequence</em>) &#8211; a sequence of parameters for the likelihood object, e.g. the
likelihoods.Gaussian object takes a variance parameter, so this
should be <code class="code docutils literal"><span class="pre">[var]</span></code>.</li>
<li><strong>basis_hypers</strong> (<em>sequence</em>) &#8211; A sequence of hyperparameters of the basis object.</li>
<li><strong>likelihood_args</strong> (<em>sequence, optional</em>) &#8211; sequence of arguments to pass to the likelihood function. These
are non-learnable parameters. They can be scalars or arrays of
length Ns.</li>
<li><strong>nsamples</strong> (<em>int, optional</em>) &#8211; The number of samples to draw from the posterior in order to
approximate the predictive mean and variance.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>p</strong> (<em>ndarray</em>) &#8211; The probability of ys &lt;= quantile for the query inputs, Xs of shape
(Ns,).</li>
<li><strong>p_min</strong> (<em>ndarray</em>) &#8211; The minimum sampled values of the predicted probability (same shape
as p)</li>
<li><strong>p_max</strong> (<em>ndarray</em>) &#8211; The maximum sampled values of the predicted probability (same shape
as p)</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="revrand.glm.predict_interval">
<code class="descclassname">revrand.glm.</code><code class="descname">predict_interval</code><span class="sig-paren">(</span><em>alpha</em>, <em>Xs</em>, <em>likelihood</em>, <em>basis</em>, <em>m</em>, <em>C</em>, <em>likelihood_hypers</em>, <em>basis_hypers</em>, <em>likelihood_args=()</em>, <em>nsamples=100</em>, <em>multiproc=True</em><span class="sig-paren">)</span><a class="headerlink" href="#revrand.glm.predict_interval" title="Permalink to this definition">¶</a></dt>
<dd><p>Predictive percentile interval (upper and lower quantiles) for a Bayesian
GLM.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>alpha</strong> (<em>float</em>) &#8211; The percentile confidence interval (e.g. 95%) to return.</li>
<li><strong>Xs</strong> (<em>ndarray</em>) &#8211; (Ns,d) array query input dataset (Ns samples, D dimensions).</li>
<li><strong>likelihood</strong> (<em>Object</em>) &#8211; A likelihood object, see the likelihoods module.</li>
<li><strong>basis</strong> (<em>Basis</em>) &#8211; A basis object, see the basis_functions module.</li>
<li><strong>m</strong> (<em>ndarray</em>) &#8211; (D,) array of regression weights (posterior).</li>
<li><strong>C</strong> (<em>ndarray</em>) &#8211; (D,) or (D, D) array of regression weight covariances (posterior).</li>
<li><strong>likelihood_hypers</strong> (<em>sequence</em>) &#8211; a sequence of parameters for the likelihood object, e.g. the
likelihoods.Gaussian object takes a variance parameter, so this
should be <code class="code docutils literal"><span class="pre">[var]</span></code>.</li>
<li><strong>basis_hypers</strong> (<em>sequence</em>) &#8211; A sequence of hyperparameters of the basis object.</li>
<li><strong>likelihood_args</strong> (<em>sequence, optional</em>) &#8211; sequence of arguments to pass to the likelihood function. These
are non-learnable parameters. They can be scalars or arrays of
length Ns.</li>
<li><strong>nsamples</strong> (<em>int, optional</em>) &#8211; The number of samples to draw from the posterior in order to
approximate the predictive mean and variance.</li>
<li><strong>multiproc</strong> (<em>bool, optional</em>) &#8211; Use multiprocessing to paralellise this prediction computation.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>ql</strong> (<em>ndarray</em>) &#8211; The lower end point of the interval with shape (Ns,)</li>
<li><strong>qu</strong> (<em>ndarray</em>) &#8211; The upper end point of the interval with shape (Ns,)</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="revrand.glm.predict_moments">
<code class="descclassname">revrand.glm.</code><code class="descname">predict_moments</code><span class="sig-paren">(</span><em>Xs</em>, <em>likelihood</em>, <em>basis</em>, <em>m</em>, <em>C</em>, <em>likelihood_hypers</em>, <em>basis_hypers</em>, <em>likelihood_args=()</em>, <em>nsamples=100</em><span class="sig-paren">)</span><a class="headerlink" href="#revrand.glm.predict_moments" title="Permalink to this definition">¶</a></dt>
<dd><p>Predictive moments, in particular mean and variance, of a Bayesian GLM.</p>
<p>This function uses Monte-Carlo sampling to evaluate the predictive mean and
variance of a Bayesian GLM. The exact expressions evaluated are,</p>
<div class="math">
\[ \begin{align}\begin{aligned}\mathbb{E}[y^*] = \int g(\mathbf{w}^T \boldsymbol\phi^{*})
    p(\mathbf{w} | \mathbf{y}, \boldsymbol\Phi) d\mathbf{w},\\\mathbb{V}[y^*] = \int \left(g(\mathbf{w}^T \boldsymbol\phi^{*})
    - \mathbb{E}[y^*]\right)^2
    p(\mathbf{w} | \mathbf{y}, \boldsymbol\Phi) d\mathbf{w},\end{aligned}\end{align} \]</div>
<p>where <span class="math">\(g(\cdot)\)</span> is the activation (inverse link) link function used
by the GLM, and <span class="math">\(p(\mathbf{w} | \mathbf{y}, \boldsymbol\Phi)\)</span> is the
posterior distribution over weights (from <code class="code docutils literal"><span class="pre">learn</span></code>). Here are few
concrete examples of how we can use these values,</p>
<ul class="simple">
<li>Gaussian likelihood: these are just the predicted mean and variance, see
<code class="code docutils literal"><span class="pre">revrand.regression.predict</span></code></li>
<li>Bernoulli likelihood: The expected value is the probability, <span class="math">\(p(y^*
= 1)\)</span>, i.e. the probability of class one. The variance may not be so
useful.</li>
<li>Poisson likelihood: The expected value is similar conceptually to the
Gaussian case, and is also a <em>continuous</em> value. The median (50%
quantile) from <code class="code docutils literal"><span class="pre">predict_interval</span></code> is a discrete value. Again, the
variance in this instance may not be so useful.</li>
</ul>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>Xs</strong> (<em>ndarray</em>) &#8211; (Ns,d) array query input dataset (Ns samples, D dimensions).</li>
<li><strong>likelihood</strong> (<em>Object</em>) &#8211; A likelihood object, see the likelihoods module.</li>
<li><strong>basis</strong> (<em>Basis</em>) &#8211; A basis object, see the basis_functions module.</li>
<li><strong>m</strong> (<em>ndarray</em>) &#8211; (D,) array of regression weights (posterior).</li>
<li><strong>C</strong> (<em>ndarray</em>) &#8211; (D,) or (D, D) array of regression weight covariances (posterior).</li>
<li><strong>likelihood_hypers</strong> (<em>sequence</em>) &#8211; a sequence of parameters for the likelihood object, e.g. the
likelihoods.Gaussian object takes a variance parameter, so this
should be <code class="code docutils literal"><span class="pre">[var]</span></code>.</li>
<li><strong>basis_hypers</strong> (<em>sequence</em>) &#8211; A sequence of hyperparameters of the basis object.</li>
<li><strong>likelihood_args</strong> (<em>sequence, optional</em>) &#8211; sequence of arguments to pass to the likelihood function. These
are non-learnable parameters. They can be scalars or arrays of
length Ns.</li>
<li><strong>nsamples</strong> (<em>int, optional</em>) &#8211; The number of samples to draw from the posterior in order to
approximate the predictive mean and variance.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>Ey</strong> (<em>ndarray</em>) &#8211; The expected value of ys for the query inputs, Xs of shape (Ns,).</li>
<li><strong>Vy</strong> (<em>ndarray</em>) &#8211; The expected variance of ys (excluding likelihood noise terms) for
the query inputs, Xs of shape (Ns,).</li>
<li><strong>Ey_min</strong> (<em>ndarray</em>) &#8211; The minimum sampled values of the predicted mean (same shape as Ey)</li>
<li><strong>Ey_max</strong> (<em>ndarray</em>) &#8211; The maximum sampled values of the predicted mean (same shape as Ey)</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="slm.html"
                        title="previous chapter">Standard Linear Model</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="likelihoods.html"
                        title="next chapter">Likelihood Classes</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="likelihoods.html" title="Likelihood Classes"
             >next</a> |</li>
        <li class="right" >
          <a href="slm.html" title="Standard Linear Model"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">revrand 0.4.1 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &copy; Copyright 2015, Daniel Steinberg, Louis Tiao, Lachlan McCalman, Alistair Reid.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.4.
    </div>
  </body>
</html>